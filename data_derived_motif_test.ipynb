{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Derived Contextual Motif Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook serves as a walkthrough for the data-derived contextual motif tools described in https://arxiv.org/abs/1703.02144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "from sklearn.externals import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib import glucose_processing as GP\n",
    "from lib import data_derived_motifs as ddm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data here\n",
    "# Random data to demonstrate how the pipeline runs\n",
    "patients = {}\n",
    "for i in range(1,10):\n",
    "    patients[i] = {'glucose':[np.random.randint(0,3,1152)*60+69 for j in range(13)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Discover Motifs\n",
    "To discover motifs, we use a simplified version of the MDLats pipeline, explained in our paper. The full MDLats approach is presented here: http://ieeexplore.ieee.org/document/7056438/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133848/133848 [00:09<00:00, 14474.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35692.8\n",
      "21 30\n"
     ]
    }
   ],
   "source": [
    "# We must predefine relevant motif discovery parameters\n",
    "motif_length = 8\n",
    "stride_length = 1 \n",
    "motif_min_count = 5\n",
    "n_motifs = 15\n",
    "\n",
    "# These parameters inform the data preprocessing and \n",
    "center = True\n",
    "scale = True\n",
    "n_letters = 30\n",
    "\n",
    "# problem specific parameters\n",
    "hypo_thresh = 1\n",
    "hyper_thresh = 3\n",
    "\n",
    "# first, we divide data into proto-motif candidates\n",
    "cands, chunkdiv = ddm.sess_to_cand(patients, motif_length, stride_length)\n",
    "# second, we preprocess the candidates to center and scale if set\n",
    "cands = ddm.cand_preprocessing(cands, center, scale)\n",
    "# we represent continuous waveform data with a variant of SAX, explained in our paper\n",
    "sax_dat, div = ddm.balancing_SAX(cands, n_letters)\n",
    "# the discritized candidates are transformed into motif prototypes\n",
    "motif_proto, motif_proto_set = ddm.protomotifs(sax_dat, motif_min_count)\n",
    "\n",
    "# we cluster the prototypes to get n_motif maximally distinct motifs\n",
    "kmini = sklearn.cluster.MiniBatchKMeans(n_clusters=n_motifs, batch_size=400)\n",
    "klabels = kmini.fit_predict(motif_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data into contextual motif representation\n",
    "Now that we have our baseline motifs, we look for contextual motifs. This is accomplished by appending each motif representation with an indicator variable for the context under which it occurred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/351 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 3/351 [00:00<00:14, 24.14it/s]\u001b[A\n",
      "  2%|▏         | 6/351 [00:00<00:14, 24.50it/s]\u001b[A\n",
      "  3%|▎         | 9/351 [00:00<00:14, 24.21it/s]\u001b[A\n",
      "  3%|▎         | 12/351 [00:00<00:13, 24.53it/s]\u001b[A\n",
      "  4%|▍         | 15/351 [00:00<00:13, 24.47it/s]\u001b[A\n",
      "  5%|▌         | 18/351 [00:00<00:13, 24.62it/s]\u001b[A\n",
      "  6%|▌         | 21/351 [00:00<00:13, 24.58it/s]\u001b[A\n",
      "  7%|▋         | 24/351 [00:00<00:13, 24.81it/s]\u001b[A\n",
      "  8%|▊         | 27/351 [00:01<00:13, 24.31it/s]\u001b[A\n",
      "  9%|▉         | 31/351 [00:01<00:12, 25.67it/s]\u001b[A\n",
      " 10%|▉         | 34/351 [00:01<00:12, 25.22it/s]\u001b[A\n",
      " 11%|█         | 37/351 [00:01<00:12, 25.41it/s]\u001b[A\n",
      " 11%|█▏        | 40/351 [00:01<00:12, 25.46it/s]\u001b[A\n",
      " 12%|█▏        | 43/351 [00:01<00:12, 25.40it/s]\u001b[A\n",
      " 13%|█▎        | 46/351 [00:01<00:12, 25.41it/s]\u001b[A\n",
      " 14%|█▍        | 49/351 [00:01<00:11, 25.40it/s]\u001b[A\n",
      " 15%|█▍        | 52/351 [00:02<00:11, 24.97it/s]\u001b[A\n",
      " 16%|█▌        | 55/351 [00:02<00:11, 25.79it/s]\u001b[A\n",
      " 17%|█▋        | 58/351 [00:02<00:12, 23.87it/s]\u001b[A\n",
      " 18%|█▊        | 62/351 [00:02<00:11, 25.74it/s]\u001b[A\n",
      " 19%|█▉        | 66/351 [00:02<00:09, 28.50it/s]\u001b[A\n",
      " 20%|██        | 71/351 [00:02<00:08, 31.14it/s]\u001b[A\n",
      " 21%|██▏       | 75/351 [00:02<00:09, 29.27it/s]\u001b[A\n",
      " 23%|██▎       | 79/351 [00:03<00:09, 27.93it/s]\u001b[A\n",
      " 23%|██▎       | 82/351 [00:03<00:09, 27.48it/s]\u001b[A\n",
      " 24%|██▍       | 85/351 [00:03<00:09, 26.73it/s]\u001b[A\n",
      " 25%|██▌       | 88/351 [00:03<00:09, 26.50it/s]\u001b[A\n",
      " 26%|██▌       | 91/351 [00:03<00:09, 26.68it/s]\u001b[A\n",
      " 27%|██▋       | 95/351 [00:03<00:09, 28.29it/s]\u001b[A\n",
      " 28%|██▊       | 99/351 [00:03<00:08, 29.62it/s]\u001b[A\n",
      " 29%|██▉       | 103/351 [00:03<00:08, 28.92it/s]\u001b[A\n",
      " 30%|███       | 106/351 [00:03<00:08, 29.05it/s]\u001b[A\n",
      " 31%|███▏      | 110/351 [00:04<00:07, 30.80it/s]\u001b[A\n",
      " 32%|███▏      | 114/351 [00:04<00:08, 28.84it/s]\u001b[A\n",
      " 33%|███▎      | 117/351 [00:04<00:08, 28.03it/s]\u001b[A\n",
      " 34%|███▍      | 120/351 [00:04<00:08, 27.39it/s]\u001b[A\n",
      " 35%|███▌      | 124/351 [00:04<00:07, 30.25it/s]\u001b[A\n",
      " 36%|███▋      | 128/351 [00:04<00:07, 30.24it/s]\u001b[A\n",
      " 38%|███▊      | 132/351 [00:04<00:07, 29.50it/s]\u001b[A\n",
      " 39%|███▊      | 136/351 [00:04<00:07, 28.39it/s]\u001b[A\n",
      " 40%|███▉      | 139/351 [00:05<00:08, 25.82it/s]\u001b[A\n",
      " 40%|████      | 142/351 [00:05<00:08, 26.09it/s]\u001b[A\n",
      " 41%|████▏     | 145/351 [00:05<00:07, 26.03it/s]\u001b[A\n",
      " 42%|████▏     | 148/351 [00:05<00:07, 25.44it/s]\u001b[A\n",
      " 43%|████▎     | 152/351 [00:05<00:07, 28.30it/s]\u001b[A\n",
      " 45%|████▍     | 157/351 [00:05<00:06, 30.82it/s]\u001b[A\n",
      " 46%|████▌     | 161/351 [00:05<00:06, 30.93it/s]\u001b[A\n",
      " 47%|████▋     | 165/351 [00:05<00:05, 31.41it/s]\u001b[A\n",
      " 48%|████▊     | 169/351 [00:06<00:05, 32.29it/s]\u001b[A\n",
      " 49%|████▉     | 173/351 [00:06<00:05, 33.01it/s]\u001b[A\n",
      " 50%|█████     | 177/351 [00:06<00:05, 30.07it/s]\u001b[A\n",
      " 52%|█████▏    | 181/351 [00:06<00:05, 29.91it/s]\u001b[A\n",
      " 53%|█████▎    | 185/351 [00:06<00:05, 28.85it/s]\u001b[A\n",
      " 54%|█████▎    | 188/351 [00:06<00:05, 27.83it/s]\u001b[A\n",
      " 54%|█████▍    | 191/351 [00:06<00:05, 27.99it/s]\u001b[A\n",
      " 55%|█████▌    | 194/351 [00:06<00:05, 28.49it/s]\u001b[A\n",
      " 56%|█████▌    | 197/351 [00:07<00:05, 27.45it/s]\u001b[A\n",
      " 57%|█████▋    | 201/351 [00:07<00:05, 29.03it/s]\u001b[A\n",
      " 58%|█████▊    | 205/351 [00:07<00:04, 30.11it/s]\u001b[A\n",
      " 60%|█████▉    | 209/351 [00:07<00:04, 30.24it/s]\u001b[A\n",
      " 61%|██████    | 213/351 [00:07<00:04, 31.44it/s]\u001b[A\n",
      " 62%|██████▏   | 217/351 [00:07<00:04, 31.13it/s]\u001b[A\n",
      " 63%|██████▎   | 221/351 [00:07<00:04, 29.68it/s]\u001b[A\n",
      " 64%|██████▍   | 224/351 [00:07<00:04, 28.80it/s]\u001b[A\n",
      " 65%|██████▍   | 227/351 [00:08<00:04, 28.18it/s]\u001b[A\n",
      " 66%|██████▌   | 230/351 [00:08<00:04, 27.55it/s]\u001b[A\n",
      " 66%|██████▋   | 233/351 [00:08<00:04, 27.11it/s]\u001b[A\n",
      " 67%|██████▋   | 236/351 [00:08<00:04, 26.28it/s]\u001b[A\n",
      " 68%|██████▊   | 239/351 [00:08<00:04, 26.26it/s]\u001b[A\n",
      " 69%|██████▉   | 242/351 [00:08<00:04, 26.11it/s]\u001b[A\n",
      " 70%|██████▉   | 245/351 [00:08<00:04, 25.79it/s]\u001b[A\n",
      " 71%|███████   | 248/351 [00:08<00:04, 25.69it/s]\u001b[A\n",
      " 72%|███████▏  | 251/351 [00:09<00:03, 25.58it/s]\u001b[A\n",
      " 72%|███████▏  | 254/351 [00:09<00:03, 24.76it/s]\u001b[A\n",
      " 73%|███████▎  | 257/351 [00:09<00:03, 24.39it/s]\u001b[A\n",
      " 74%|███████▍  | 260/351 [00:09<00:03, 24.59it/s]\u001b[A\n",
      " 75%|███████▍  | 263/351 [00:09<00:03, 24.87it/s]\u001b[A\n",
      " 76%|███████▌  | 266/351 [00:09<00:03, 24.75it/s]\u001b[A\n",
      " 77%|███████▋  | 269/351 [00:09<00:03, 25.08it/s]\u001b[A\n",
      " 77%|███████▋  | 272/351 [00:09<00:03, 25.68it/s]\u001b[A\n",
      " 78%|███████▊  | 275/351 [00:09<00:02, 25.70it/s]\u001b[A\n",
      " 79%|███████▉  | 278/351 [00:10<00:02, 25.43it/s]\u001b[A\n",
      " 80%|████████  | 282/351 [00:10<00:02, 27.15it/s]\u001b[A\n",
      " 81%|████████▏ | 286/351 [00:10<00:02, 28.73it/s]\u001b[A\n",
      " 83%|████████▎ | 290/351 [00:10<00:02, 29.99it/s]\u001b[A\n",
      " 84%|████████▍ | 294/351 [00:10<00:02, 28.00it/s]\u001b[A\n",
      " 85%|████████▍ | 297/351 [00:10<00:01, 28.14it/s]\u001b[A\n",
      " 86%|████████▌ | 301/351 [00:10<00:01, 29.71it/s]\u001b[A\n",
      " 87%|████████▋ | 305/351 [00:10<00:01, 29.83it/s]\u001b[A\n",
      " 88%|████████▊ | 309/351 [00:11<00:01, 31.28it/s]\u001b[A\n",
      " 89%|████████▉ | 313/351 [00:11<00:01, 30.79it/s]\u001b[A\n",
      " 90%|█████████ | 317/351 [00:11<00:01, 29.28it/s]\u001b[A\n",
      " 91%|█████████ | 320/351 [00:11<00:01, 28.02it/s]\u001b[A\n",
      " 92%|█████████▏| 323/351 [00:11<00:01, 27.00it/s]\u001b[A\n",
      " 93%|█████████▎| 326/351 [00:11<00:00, 26.45it/s]\u001b[A\n",
      " 94%|█████████▎| 329/351 [00:11<00:00, 26.35it/s]\u001b[A\n",
      " 95%|█████████▍| 332/351 [00:11<00:00, 26.47it/s]\u001b[A\n",
      " 95%|█████████▌| 335/351 [00:12<00:00, 26.39it/s]\u001b[A\n",
      " 96%|█████████▋| 338/351 [00:12<00:00, 25.24it/s]\u001b[A\n",
      " 97%|█████████▋| 341/351 [00:12<00:00, 24.90it/s]\u001b[A\n",
      " 98%|█████████▊| 344/351 [00:12<00:00, 25.32it/s]\u001b[A\n",
      " 99%|█████████▉| 348/351 [00:12<00:00, 28.14it/s]\u001b[A\n",
      "100%|██████████| 351/351 [00:12<00:00, 27.81it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Each call to this cell generates a set of contextual motifs\n",
    "# context_func determines context, contexts used in paper: no_context, trend, and hmm\n",
    "# note that hmm relies on a previously trained HMM, trained with pomegranate\n",
    "max_interp_length = 2\n",
    "max_missing_data_x = 144 # allow half of a day to be missing for input\n",
    "max_missing_data_y = 144 # allow half of a day to be missing for label\n",
    "context_func = ddm.dummy_context\n",
    "precompute_func = None\n",
    "context_size = 4\n",
    "X, labels, y_hypo, y_hyper, y_event = ddm.get_days_and_events(patients, \n",
    "                                                              max_interp_length, \n",
    "                                                              max_missing_data_x, \n",
    "                                                              max_missing_data_y)\n",
    "day_motif= []\n",
    "for i in tqdm(range(len(X))):\n",
    "    try:\n",
    "        day_motif.append(ddm.day_to_motif_vec(X[i], \n",
    "                                      motif_length, \n",
    "                                      stride_length, \n",
    "                                      div, \n",
    "                                      motif_proto_set, \n",
    "                                      n_motifs, \n",
    "                                      kmini, \n",
    "                                      (context_func, context_size, precompute_func), \n",
    "                                      center, \n",
    "                                      scale))\n",
    "    except:\n",
    "        print(i)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.,   8.,   8.,   8.,   4.,  11.,   1.,  18.,  13.,   7.,   5.,\n",
       "        17.,   8.,  16.,   9.,   5.,   0.,  15.,   0.,  10.,   9.,   5.,\n",
       "         0.,  13.,   0.,   2.,   4.,   7.,   0.,  13.,   0.,   5.,   4.,\n",
       "         0.,   0.,   5.,   0.,   0.,   6.,   5.,   0.,   5.,   0.,   4.,\n",
       "         3.,   0.,   0.,   0.,   0.,   0.,   0.,   7.,   0.,   0.,   0.,\n",
       "         8.,   0.,   0.,   0.,   5.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of one days motif representation\n",
    "day_motif[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Scheme\n",
    "The following demonstrates how we evaluate the quality of our motif representation. We use the learned motif representation as input to a logistic regression model and test predictive performance. We tune hyperparameters for the ML model using random search over a specified number of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.60s/it]\u001b[A\n",
      "2it [00:02,  1.45s/it]\u001b[A\n",
      "3it [00:03,  1.26s/it]\u001b[A\n",
      "4it [00:04,  1.21s/it]\u001b[A\n",
      "5it [00:05,  1.07s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hyper': [0.5, 0.5, 0.5, 0.49025974025974028, 0.4759036144578313],\n",
       " 'hypo': [0.57662337662337659, 0.43860946745562129, 0.5, 0.5, 0.5]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for paper exepriments, performed random search over the following parameter space with\n",
    "# budget == 200, num_split == 100\n",
    "params = {'C':10.**np.arange(-10, 10, .01), \n",
    "         'penalty':['l1','l2'], \n",
    "         'class_weight':[None, 'balanced']}\n",
    "budget = 10\n",
    "num_split = 5\n",
    "\n",
    "# with random data, performs randomly (as we would expect)\n",
    "ddm.test_motif_rep(day_motif, \n",
    "                   y_hypo, \n",
    "                   y_hyper, \n",
    "                   labels, \n",
    "                   params, \n",
    "                   budget, \n",
    "                   num_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
